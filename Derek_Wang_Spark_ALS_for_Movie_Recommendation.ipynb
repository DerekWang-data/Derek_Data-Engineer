{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MovieLens 100k Dataset Description\n",
        "\n",
        "The MovieLens 100k dataset contains user ratings for movies. It is often used to build and test recommendation systems. The dataset is split into multiple files. Two of the most important are:\n",
        "\n",
        "### 1. `u.item` (Movie Information)\n",
        "\n",
        "- **Contains**: Metadata about each movie  \n",
        "- **Delimiter**: | (pipe symbol)  \n",
        "- **Columns (simplified):**\n",
        "  - `movieID` → Unique numeric ID for each movie  \n",
        "  - `movieName` → The title of the movie (e.g., *Toy Story (1995)*)  \n",
        "  - `genres` → One or more categories the movie belongs to (e.g., Action, Comedy, Romance, etc.)  \n",
        "\n",
        "**Example row:**\n",
        "\n",
        "\n",
        "1|Toy Story (1995)|Animation|Children's|Comedy\n",
        "\n",
        "This means:\n",
        "movieID = 1\n",
        "\n",
        "movieName = \"Toy Story (1995)\"\n",
        "\n",
        "Genres = Animation, Children’s, Comedy"
      ],
      "metadata": {
        "id": "qUEPl_KEPXij"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. `u.data` (User Ratings)\n",
        "\n",
        "- **Contains**: The ratings users gave to movies  \n",
        "- **Delimiter**: Whitespace (space or tab)  \n",
        "- **Columns:**\n",
        "  - `userID` → The user who rated the movie  \n",
        "  - `movieID` → The movie being rated (matches with u.item)  \n",
        "  - `rating` → A number from 1 to 5 (higher = better)  \n",
        "  - `timestamp` → When the rating was given  \n",
        "\n",
        "**Example row:**\n",
        "196 242 3 881250949\n",
        "\n",
        "**This means:**\n",
        "- userID = 196  \n",
        "- movieID = 242  \n",
        "- rating = 3 (out of 5)  \n",
        "- timestamp = 881250949 (Unix time)  \n",
        "\n",
        "___"
      ],
      "metadata": {
        "id": "jpUA3DzdPezt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spark ALS Recommendation Setup"
      ],
      "metadata": {
        "id": "TBdx_SvajWk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.functions import lit"
      ],
      "metadata": {
        "id": "9OKjVFaQjVSp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`lit()` is used to create a constant column.  \n",
        "\n",
        "For example, if you want to add a column userID = 0 for all movies, you can use lit(0).\n"
      ],
      "metadata": {
        "id": "xaP6sMJPQ5Up"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Helper Functions"
      ],
      "metadata": {
        "id": "3OER48bojf8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load up movie ID -> movie name dictionary\n",
        "def loadMovieNames():\n",
        "    movieNames = {}\n",
        "    # Note: we specify encoding='ISO-8859-1' to correctly handle special characters in the file.\n",
        "    with open(\"u.item\", encoding='ISO-8859-1') as f:\n",
        "        for line in f:\n",
        "            fields = line.split('|')\n",
        "            movieNames[int(fields[0])] = fields[1]\n",
        "    return movieNames\n",
        "    #movieNames[id]= movieName\n",
        "\n",
        "# Convert u.data lines into (userID, movieID, rating) rows\n",
        "def parseInput(line):\n",
        "    fields = line.value.split()\n",
        "    return Row(userID=int(fields[0]), movieID=int(fields[1]), rating=float(fields[2]))\n"
      ],
      "metadata": {
        "id": "MUd-DmVTjlko"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding the | Separator and Iteration in the Code\n",
        "\n",
        "- The character | is **already in the dataset** as a delimiter (separator).  \n",
        "- It separates each column of information in the file:  \n",
        "  - **First column**: Movie ID  \n",
        "  - **Second column**: Movie name  \n",
        "  - **Third column**: Movie genre  \n",
        "  - … and so on  \n",
        "\n",
        "\n",
        "\n",
        "### Iteration with for line in f:\n",
        "\n",
        "- The key point: it’s not fields[0] that iterates, but for line in f.  \n",
        "- Each time through the loop, line becomes the **next row** in the file.  \n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "9lL3Ex75bfUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Spark"
      ],
      "metadata": {
        "id": "G6dMEB0tjo69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"MovieRecs\").getOrCreate()\n",
        "spark.conf.set(\"spark.sql.crossJoin.enabled\", \"true\")"
      ],
      "metadata": {
        "id": "n5PMJz23mrPs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Movie Names"
      ],
      "metadata": {
        "id": "Tx6cWzq0mwh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload multiple files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# View the names of uploaded files\n",
        "for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])\n",
        "    ))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "id": "FG25S1HLWB1G",
        "outputId": "24b1e23c-9c8f-4dfd-bd7c-2da37c75165b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8ffdb528-847e-46e6-aea6-8ce3edd949fe\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8ffdb528-847e-46e6-aea6-8ce3edd949fe\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving u.data to u.data\n",
            "Saving u.item to u (1).item\n",
            "User uploaded file \"u.data\" with length 2079229 bytes\n",
            "User uploaded file \"u (1).item\" with length 236344 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load up movie ID -> name dictionary\n",
        "import pandas as pd\n",
        "movieNames = loadMovieNames()"
      ],
      "metadata": {
        "id": "dc5VqpdomzDl"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and Prepare Ratings Data"
      ],
      "metadata": {
        "id": "1NoWmFjXnGhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load raw data from HDFS\n",
        "lines = spark.read.text(\"u.data\").rdd\n",
        "\n",
        "# Convert it to a RDD of Row objects with (userID, movieID, rating)\n",
        "ratingsRDD = lines.map(parseInput)\n",
        "\n",
        "# Convert RDD to DataFrame and cache\n",
        "ratings = spark.createDataFrame(ratingsRDD).cache()\n"
      ],
      "metadata": {
        "id": "Z6jnishLnH8K"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RDD = Resilient Distributed Dataset\n",
        "\n",
        "Resilient: Has the ability to recover — if one node fails, the data can be recovered from other nodes.\n",
        "\n",
        "Distributed: The data is spread across multiple machines in a cluster, not stored on a single computer.\n",
        "\n",
        "Dataset: A collection of data.\n",
        "\n",
        "So, RDD can be understood as a large distributed list (or array), which Spark can split into many smaller pieces and process on different machines.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "SKIvGnG_fL8_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1️⃣ `lines = spark.read.text(\"u.data\").rdd`\n",
        "\n",
        "- spark.read.text(\"u.data\") → Reads the uploaded u.data file.  \n",
        "  This file contains user ratings for movies. Each line looks like:  \n",
        "  196 242 3 881250949\n",
        "\n",
        "\n",
        "**Explanation of each value:**\n",
        "- `196` → userID  \n",
        "- `242` → movieID  \n",
        "- `3` → rating  \n",
        "- `881250949` → timestamp  \n",
        "\n",
        "- `.rdd` → Converts the read data into an **RDD (Resilient Distributed Dataset)**.  \n",
        "RDD is the fundamental data structure in Spark for distributed computing.  \n",
        "You can think of it as a large table where each row is a record, but Spark can split it across multiple nodes for parallel processing.\n",
        "\n",
        "2️⃣ **`ratingsRDD = lines.map(parseInput)`**\n",
        "\n",
        "- lines.map(parseInput) → Applies the previously defined parseInput function to each row.  \n",
        "\n",
        "**What parseInput does:**\n",
        "- Takes a line like \"196 242 3 881250949\", splits it, and keeps the first 3 values.  \n",
        "- Converts it into a Row object: Row(userID=196, movieID=242, rating=3.0)  \n",
        "\n",
        "- Row is similar to a Python dictionary but works better in Spark DataFrames.  \n",
        "\n",
        "**Result:**\n",
        "- ratingsRDD is an RDD containing all ratings, where each record is a Row object.\n",
        "\n",
        "3️⃣ **`ratings = spark.createDataFrame(ratingsRDD).cache()`**\n",
        "\n",
        "- spark.createDataFrame(ratingsRDD) → Converts the RDD into a **DataFrame**.  \n",
        "Think of a DataFrame like an Excel table:\n",
        "\n",
        "| userID | movieID | rating |\n",
        "|--------|---------|--------|\n",
        "| 196    | 242     | 3.0    |\n",
        "\n",
        "- A DataFrame makes it easier to filter, sort, aggregate, and perform other operations.  \n",
        "- .cache() → Stores the DataFrame in memory so subsequent operations run faster.\n",
        "\n",
        "___\n"
      ],
      "metadata": {
        "id": "jcBxjEF7fRA2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train ALS Model"
      ],
      "metadata": {
        "id": "SOdetXIWnTQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an ALS collaborative filtering model from the complete data set\n",
        "als = ALS(maxIter=5, regParam=0.01, userCol=\"userID\", itemCol=\"movieID\", ratingCol=\"rating\")\n",
        "model = als.fit(ratings)\n"
      ],
      "metadata": {
        "id": "eMoNYaXcnV0L"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explaination:\n",
        "\n",
        "<br>\n",
        "\n",
        "ALS = Alternating Least Squares (ALS)\n",
        "Sounds complicated, but it can actually be understood like this:\n",
        "\n",
        "It treats each user as a vector (an array of numbers) that records their \"preference features\" for different movies. It treats each movie as a vector that records the movie's \"features\". By multiplying the user vector and the movie vector, it can predict how a user might rate a movie.\n",
        "\n",
        "regParam=0.01 → Prevents the model from overfitting (simple understanding: don't memorize the ratings, but learn the patterns)\n",
        "\n",
        "UserCol/itemCol/ratingCol → Tells the algorithm which column is the user, which is the movie, and which is the rating.\n"
      ],
      "metadata": {
        "id": "Tdn7eMFTheQU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Vectors are basically lists or arrays of numbers.\n",
        "\n",
        "Example:\n",
        "\n",
        "[1, 0, 1]  \n",
        "[0.8, 0.1, 0.9]  \n",
        "\n",
        "Each number represents the strength of a certain feature.\n",
        "\n",
        "Example: Movie feature vectors\n",
        "\n",
        "| Feature | Action | Comedy | Animation |\n",
        "|---------|--------|--------|-----------|\n",
        "| Toy Story | 0      | 0.1    | 1         |\n",
        "| Die Hard  | 1      | 0      | 0         |\n",
        "\n",
        "0 = does not have this feature  \n",
        "1 = very strong feature  \n",
        "0.1 = a little of this feature  \n",
        "\n",
        "User vectors are similar:\n",
        "\n",
        "| User  | Action | Comedy | Animation |\n",
        "|-------|--------|--------|-----------|\n",
        "| Alice | 0.9    | 0.2    | 0.1       |\n",
        "| Bob   | 0.1    | 0.7    | 0.9       |\n",
        "\n",
        "Higher numbers → stronger preference for that feature.\n",
        "\n",
        "\n",
        "\n",
        "### How ALS uses vectors to predict ratings\n",
        "\n",
        "Suppose we want to predict Alice's rating for Toy Story:\n",
        "\n",
        "Alice's vector = [0.9, 0.2, 0.1]  \n",
        "Toy Story's vector = [0, 0.1, 1]  \n",
        "\n",
        "The predicted rating is the **dot product** of the two vectors:\n",
        "Predicted rating = (0.9 * 0) + (0.2 * 0.1) + (0.1 * 1) = 0 + 0.02 + 0.1 = 0.12\n",
        "\n"
      ],
      "metadata": {
        "id": "VERnbf8JhqDW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The larger the dot product → the more the user is predicted to like the movie.\n",
        "\n",
        " Intuition: The more the user's preference vector aligns with the movie's feature vector, the higher the predicted rating.\n",
        "\n",
        "---\n",
        "\n",
        "### Why ALS uses \"Alternating Least Squares\"\n",
        "\n",
        "We do not know the user vectors or the movie vectors initially, but we know some ratings (e.g., Alice gave Die Hard a 5).\n",
        "\n",
        "ALS approach:\n",
        "\n",
        "1. Randomly assume movie vectors, then solve for user vectors so predicted ratings are close to real ratings.  \n",
        "2. Fix user vectors, then update movie vectors.  \n",
        "3. Repeat alternately until predicted ratings are close to real ratings.  \n",
        "\n",
        "Finally, we get vectors for each user and each movie, which allows us to predict ratings for any unseen movie.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "6vNDN8GYh090"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print out ratings from user 0"
      ],
      "metadata": {
        "id": "RsT0_9Vanbcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nRatings for user ID 0:\")\n",
        "userRatings = ratings.filter(\"userID = 0\")\n",
        "for rating in userRatings.collect():\n",
        "    print(movieNames[rating['movieID']], rating['rating'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vAj2UJLnj1O",
        "outputId": "9b43bb36-fdf5-4233-f549-1215bbdfae15"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ratings for user ID 0:\n",
            "Star Wars (1977) 5.0\n",
            "Empire Strikes Back, The (1980) 5.0\n",
            "Gone with the Wind (1939) 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "rating = Row(userID=0, movieID=1, rating=5.0)\n",
        "rating['movieID'] → 1\n",
        "\n",
        "movieNames[1] → \"Toy Story (1995)\"\n",
        "\n",
        "rating['rating'] → 5.0\n",
        "\n",
        "it is the movieID in rating table."
      ],
      "metadata": {
        "id": "h8bU7aQKky14"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Top 20 Recommendations for User 0"
      ],
      "metadata": {
        "id": "6cs2t4eEnwM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTop 20 recommendations:\")\n",
        "# Find movies rated more than 100 times\n",
        "ratingCounts = ratings.groupBy(\"movieID\").count().filter(\"count > 100\")\n",
        "\n",
        "# Construct a \"test\" dataframe for user 0 with every movie rated more than 100 times\n",
        "popularMovies = ratingCounts.select(\"movieID\").withColumn('userID', lit(0))\n",
        "\n",
        "# Run model on that list of popular movies for user ID 0\n",
        "recommendations = model.transform(popularMovies)\n",
        "\n",
        "# Get the top 20 movies with the highest predicted rating for this user\n",
        "topRecommendations = recommendations.sort(recommendations.prediction.desc()).take(20)\n",
        "\n",
        "for recommendation in topRecommendations:\n",
        "    print(movieNames[recommendation['movieID']], recommendation['prediction'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyMF6Uwfnywl",
        "outputId": "c8328dca-2437-44cb-cf00-cadec7b3ec5e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 20 recommendations:\n",
            "GoodFellas (1990) 6.379866123199463\n",
            "Terminator, The (1984) 6.127628803253174\n",
            "Die Hard (1988) 6.111161231994629\n",
            "Pulp Fiction (1994) 6.1084747314453125\n",
            "Army of Darkness (1993) 6.076435565948486\n",
            "Terminator 2: Judgment Day (1991) 5.834048271179199\n",
            "Good, The Bad and The Ugly, The (1966) 5.817391395568848\n",
            "Chasing Amy (1997) 5.654448986053467\n",
            "Alien (1979) 5.617126941680908\n",
            "Kingpin (1996) 5.549688339233398\n",
            "Reservoir Dogs (1992) 5.48178243637085\n",
            "Godfather: Part II, The (1974) 5.452390193939209\n",
            "Mars Attacks! (1996) 5.450388431549072\n",
            "Raiders of the Lost Ark (1981) 5.438565254211426\n",
            "Taxi Driver (1976) 5.411818027496338\n",
            "Raging Bull (1980) 5.348715305328369\n",
            "Beavis and Butt-head Do America (1996) 5.346415042877197\n",
            "Platoon (1986) 5.344396114349365\n",
            "Fifth Element, The (1997) 5.335829257965088\n",
            "Blues Brothers, The (1980) 5.3260722160339355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary:\n",
        "These are the movies ALS predicts user 0 will like the most, based on learned user and movie vectors. Higher predicted ratings indicate a stronger match between the user’s preferences and the movie features."
      ],
      "metadata": {
        "id": "s7sfoavpy4ZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explaination ALS Predictions\n",
        "\n",
        "## What ALS Stores\n",
        "\n",
        "When you train an ALS model, it learns:\n",
        "\n",
        "- **User vectors (user factors)**  \n",
        "  Example: User 0's vector `[0.9, 0.2, 0.1]`  \n",
        "  Each number represents the user's preference for a type of movie (e.g., Action, Comedy, Animation…).\n",
        "\n",
        "- **Movie vectors (item factors)**  \n",
        "  Example: Toy Story's vector `[0, 0.1, 1]`  \n",
        "  Each number represents the strength of a feature in the movie.\n",
        "\n",
        "These vectors are learned after training the model. Initially, they are random, then optimized alternately until predicted ratings are close to the real ratings.\n",
        "\n",
        "---\n",
        "\n",
        "##  Calculating Predicted Ratings with Dot Product\n",
        "\n",
        "model.transform(popularMovies) does the following:\n",
        "\n",
        "prediction=user vector⋅movie vector=u1​⋅i1​+u2​⋅i2​+u3​⋅i3​+...\n",
        "\n",
        "**Example:**\n",
        "\n",
        "- User 0 vector: `[0.9, 0.2, 0.1]`  \n",
        "- Toy Story vector: `[0, 0.1, 1]`  \n",
        "\n",
        "Predicted rating:\n",
        "0.9 * 0 + 0.2 * 0.1 + 1 * 0.1\n",
        "\n",
        "This `0.12` is the **prediction**.  \n",
        "A higher dot product → the user is more likely to rate the movie highly.\n",
        "\n",
        "---\n",
        "\n",
        "##  Why Dot Product Predicts Ratings\n",
        "\n",
        "- **Intuition:**  \n",
        "  - User vector represents the features the user likes  \n",
        "  - Movie vector represents the movie's features  \n",
        "  - The more they align, the higher the predicted rating\n",
        "\n",
        "- **Mathematical goal:**  \n",
        "  ALS aims to find vectors such that their dot product is as close as possible to the user's actual rating.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "qUejSyMyxQ5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stop Spark Session"
      ],
      "metadata": {
        "id": "7R7nHKQ-oF7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()\n"
      ],
      "metadata": {
        "id": "pAm9y4CUoIH4"
      },
      "execution_count": 31,
      "outputs": []
    }
  ]
}